# ğŸ¥· NewsNinja - Stealthy News Aggregator

Your personal **news ninja** that silently gathers headlines and Reddit reactions, then delivers audio briefings straight to your ears.  
**No scroll, just soul.**

---

## âœ¨ FEATURES

- ğŸ—ï¸ **Scrape premium news websites** *(bypassing paywalls)*
- ğŸ•µï¸â€â™‚ï¸ **Extract live Reddit reactions** *(even from JS-heavy threads)*
- ğŸ”Š **AI-powered audio summaries** *(text-to-speech with ElevenLabs)*
- âš¡ **Real-time updates** *(powered by Bright Data's MCP magic)*

---

## ğŸ› ï¸ PREREQUISITES

- Python 3.9+
- [Bright Data](https://brightdata.com) account
- [ElevenLabs](https://elevenlabs.io) account

---

## ğŸš€ QUICK START

### 1. Clone the Dojo

```bash
git clone https://github.com/AIwithhassan/newsninja.git
cd newsninja

2. Install Dependencies
pipenv install
pipenv shell

3. Ninja Secrets (Environment Setup)
cp .env.example .env

Edit .env and add your secrets:
# Bright Data
BRIGHTDATA_MCP_KEY="your_mcp_api_key"
BROWSER_AUTH="your_browser_auth_token"

# ElevenLabs 
ELEVENLABS_API_KEY="your_text_to_speech_key"

âš™ï¸ Prepare Your Weapons (Bright Data Setup)
Create an MCP Zone: Create Zone

Enable browser authentication

Copy and paste credentials into .env


ğŸƒâ€â™‚ï¸ RUNNING THE NINJA
First Terminal (Backend):
pipenv run python backend.py

Second Terminal (Frontend):
pipenv run streamlit run frontend.py

ğŸ“ PROJECT STRUCTURE
.
â”œâ”€â”€ frontend.py          # Streamlit UI
â”œâ”€â”€ backend.py           # API & data processing  
â”œâ”€â”€ utils.py             # UTILS  
â”œâ”€â”€ news_scraper.py      # News Scraper  
â”œâ”€â”€ reddit_scraper.py    # Reddit Scraper  
â”œâ”€â”€ models.py            # Pydantic model
â”œâ”€â”€ Pipfile              # Dependency scroll
â”œâ”€â”€ .env.example         # Secret map template
â””â”€â”€ requirements.txt     # Alternative dependency list


ğŸ“ NOTES
First scrape takes 15-20 seconds (good ninjas are patient).

Reddit scraping uses real browser emulation via MCP.

Keep .env file secret â€” ninjas never reveal their tools.

